# -*- coding: utf-8 -*-
"""CallForCode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e_iG5hBZjrM7mJ48r3SGYmNMU5cDS1oY
"""

!pip install geopandas -q
!pip install geopy -q

# Commented out IPython magic to ensure Python compatibility.
import requests
import json
import pandas as pd
import itertools
import geopandas
import geopy
from bs4 import BeautifulSoup
import numpy as np



import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pylab as plt
# %matplotlib inline
import seaborn as sns
from plotly.graph_objs import Scatter3d, Layout, Scene
import plotly
from wordcloud import WordCloud, STOPWORDS

"""# Get Weather Conditions"""

def getWeatherGeog(Days, longitude, latitude, key):
    """
    Get the weather by longitude and latitude of the location. Daily Weather 
    Get Longitude and Latitude on 'https://www.mapdevelopers.com/geocode_tool.php'
    doc = 'https://docs.google.com/document/d/1RY44O8ujbIA_tjlC4vYKHKzwSwEmNxuGw5sEJ9dYjG4/edit'

    Parameters
    ----------
    Days      : str
    longitude : str
    latitude  : str
    key       : str

    Returns
    -------
    pd.DataFrame
    """
    url = 'https://api.weather.com/v3/wx/forecast/daily/' + Days + 'day?geocode='+longitude + ','+ latitude + '&format=json&units=e&language=en-US&apiKey=' + key
    val = requests.get(url)
    raw_data = val.json()
    data = [{'Narrative':narr, 'Max Temperature': max, 'Min Temperature': min} for narr, max, min in zip(raw_data['narrative'], raw_data['temperatureMax'], raw_data['temperatureMin'])]
    df = pd.DataFrame(data)
    df['longitude'] = longitude
    df['latitude'] = latitude
    return df

def getWeatherCountry(countryCode, key):
    """
    Weather Alerts Headline
    doc = 'https://docs.google.com/document/d/1fhvDbnpGmptPigFkw5NbUxKtuHreyC16TtZHfyGCsBk/edit'

    Parameters
    ----------
    countryCode : str
    key         : str

    Returns
    -------
    pd.DataFrame()
    """
    url = 'https://api.weather.com/v3/alerts/headlines?countryCode='+countryCode+'&format=json&language=en-US&apiKey='+Weather_API
    val = requests.get(url)
    raw_data = val.json()
    data = []
    for item in raw_data['alerts']:
        data.append({'adminDistrict'   : item['adminDistrict'], 
                     'areaName'        : item['areaName'],
                     'countryCode'     : item['countryCode'],
                     'headlineText'    : item['headlineText'],
                     'eventDescription': item['eventDescription'],
                     'severity'        : item['severity'],
                     'source'          : item['source'],
                     'detailKey'       : item['detailKey'],
                     'latitude'        : item['latitude'],
                     'longitude'       : item['longitude'],
                     'urgency'         : item['urgency']})
    return pd.DataFrame(data)

"""## Get the weather report of the whole country """

Weather_API = '8042786b38064cbb82786b3806fcbbf9'

weatherHeadline = getWeatherCountry('US', Weather_API)

weatherHeadline

"""## Get Weather by your longitude and latitude """

# Enter Address in the format ```Street_Name```, ```City```, ```Country```
address = str(input("Enter the address you want weather information on?"))

locator = geopy.Nominatim(user_agent="myGeocoder")
location = locator.geocode(address)

# GeoCode of your location can be found on
# url = 'https://www.mapdevelopers.com/geocode_tool.php'
Days = '7' # 7 or 15 Days

DailyWeather = getWeatherGeog(Days, str(location.longitude), str(location.latitude), Weather_API)

DailyWeather

"""# Get Water Toxicity Levels"""

def aquagenuity(zipcode):
    """
    Get the toxin levels of water by Zipcode 
    api doc = 'https://aquagenuity.com/api'
    Parameters
    ----------
    zipcode : str

    Returns
    -------
    pd.DataFrame
    """
    authentication = {"auth":{"username":"VDx4jhB61ure","password":"XLmvDTdpcTDU"},"zipcode":zipcode}
    resp = requests.get('https://aquagenuity.com/GetWaterScore', json=authentication)
    data = []
    for item in resp.json()['contaminantDetails']:
        data.append({'Zip':item['Zip'],
                    'As of Date' : item['As of Date'],
                    'health_risk_type_description': item['health_risk_type_description'],
                    'toxin_type_name':item['toxin_type_name'],
                    'toxin_type_cd':item['toxin_type_cd'],
                    'toxin_limit_unit':item['toxin_limit_unit'],
                    'toxin_limit_value':item['toxin_limit_value'],
                    'utility_id':item['utility_id']})
    return pd.DataFrame(data)

data = pd.read_csv("./uszips.csv")

data = data[['state_name', 'county_name','county_fips']]
data.drop_duplicates()

WaterLevels = aquagenuity("07840")

result = pd.DataFrame()
for i in data.iterrows():
  curr = aquagenuity(str(i[1]['county_fips']))
  curr['country_name'] = i[1]['county_name']
  curr['state_name'] = i[1]['state_name']
  result = pd.concat([result, curr], axis=0)

result.reset_index(drop=True, inplace=True)
result.reindex(np.arange(len(result)))

states = result.country_name.unique()

result[result['country_name']==states[1]]

result.to_csv('./data.csv')









"""## Get the stats of water in selected countries from [AquaStat](http://www.fao.org/aquastat/statistics/query/index.html)

Units Appropriate Meaning 
![](https://drive.google.com/uc?export=view&id=1xPMo3NUkexx9uaJV6eBpGACTfrzgnAqD)
"""

# Read CSV locally
aquastat = pd.read_csv("./aquastat.csv")

"""### Clean Data retreived from aquastat"""

def data_cleaner_column(data):
    for i in data.columns:
        if data[i].isnull().sum() > (0.5 * data.shape[0]):
            data.drop(i,axis=1,inplace=True)
    return data

def data_cleaner_row(data):
    remove = []
    for i in range(len(data)):
        if data.iloc[i].isnull().sum() > (0.5 * data.shape[1]):
          remove.append(i)
    data.drop(index = data.index[remove], axis = 0, inplace=True)
    return data

aquastat = data_cleaner_column(aquastat)

aquastat = data_cleaner_row(aquastat)

aquastat.shape

aquastat



val = requests.get("https://ds.nccs.nasa.gov/thredds/catalog/gmao/odas/catalog.html")

res = BeautifulSoup(val.text, 'lxml')

res





